{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae44693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import praw\n",
    "from datetime import datetime\n",
    "\n",
    "# ========================\n",
    "# CONFIG\n",
    "# ========================\n",
    "NEWSAPI_KEY = \"4ba6c109aca749ef9d2fba6b60bb0a5f\"\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"s03ue3ekn5cHhzpqbIOzaQ\",\n",
    "    client_secret=\"FHSaYn-k5aVbbIJkWUKolmDqYcZ5FA\",\n",
    "    user_agent=\"genai-edu-scraper/0.1 by EducationImaginary25\"\n",
    ")\n",
    "\n",
    "OUTPUT_FILE = \"genai_education2.csv\"\n",
    "\n",
    "# ========================\n",
    "# KEYWORDS\n",
    "# ========================\n",
    "EDU_KEYWORDS = [\n",
    "    \"education\", \"learning\", \"school\", \"university\",\n",
    "    \"classroom\", \"student\", \"teacher\", \"curriculum\", \"edtech\", \"academic\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# HELPERS\n",
    "# ========================\n",
    "def is_genai_edu(text):\n",
    "    \"\"\"Check if text explicitly mentions 'generative ai' and has an education context\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    low = text.lower()\n",
    "    return \"generative ai\" in low and any(e in low for e in EDU_KEYWORDS)\n",
    "\n",
    "def safe_date(datestr):\n",
    "    try:\n",
    "        return datetime.fromisoformat(datestr.replace(\"Z\", \"+00:00\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def dedupe(records):\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for r in records:\n",
    "        key = r.get(\"url\") or r.get(\"title\")\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            out.append(r)\n",
    "    return out\n",
    "\n",
    "# ========================\n",
    "# SOURCES\n",
    "# ========================\n",
    "def fetch_newsapi(query=\"generative ai education\"):\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\"q\": query, \"language\": \"en\", \"pageSize\": 100, \"page\": 1, \"apiKey\": NEWSAPI_KEY}\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        print(\"NewsAPI error\", r.status_code, r.text)\n",
    "        return []\n",
    "    data = r.json()\n",
    "    out = []\n",
    "    for a in data.get(\"articles\", []):\n",
    "        title = a.get(\"title\") or \"\"\n",
    "        desc = a.get(\"description\") or \"\"\n",
    "        body = a.get(\"content\") or \"\"\n",
    "        content = \" \".join([title, desc, body]).strip()\n",
    "        if is_genai_edu(content):\n",
    "            out.append({\n",
    "                \"title\": title,\n",
    "                \"content\": content,\n",
    "                \"published_at\": safe_date(a.get(\"publishedAt\",\"\")),\n",
    "                \"url\": a.get(\"url\"),\n",
    "                \"source\": a.get(\"source\",{}).get(\"name\",\"newsapi\")\n",
    "            })\n",
    "    return out\n",
    "\n",
    "def fetch_medium():\n",
    "    url = \"https://api.rss2json.com/v1/api.json\"\n",
    "    params = {\"rss_url\": \"https://medium.com/feed/tag/generative-ai\"}\n",
    "    r = requests.get(url, params=params, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        print(\"Medium fetch error\", r.status_code)\n",
    "        return []\n",
    "    data = r.json()\n",
    "    out = []\n",
    "    for item in data.get(\"items\", []):\n",
    "        title = item.get(\"title\", \"\")\n",
    "        content = item.get(\"content\", \"\")\n",
    "        text = f\"{title} {content}\"\n",
    "        if is_genai_edu(text):\n",
    "            out.append({\n",
    "                \"title\": title,\n",
    "                \"content\": text,\n",
    "                \"published_at\": safe_date(item.get(\"pubDate\",\"\")),\n",
    "                \"url\": item.get(\"link\"),\n",
    "                \"source\": \"medium\"\n",
    "            })\n",
    "    return out\n",
    "\n",
    "def fetch_reddit():\n",
    "    out = []\n",
    "    subreddits = \"edtech+education+technology+ArtificialIntelligence\"\n",
    "\n",
    "    # Search submissions\n",
    "    for submission in reddit.subreddit(subreddits).search(\"generative ai education\", limit=50):\n",
    "        text = f\"{submission.title} {submission.selftext}\"\n",
    "        if is_genai_edu(text):\n",
    "            out.append({\n",
    "                \"title\": submission.title,\n",
    "                \"content\": text,\n",
    "                \"published_at\": datetime.utcfromtimestamp(submission.created_utc),\n",
    "                \"url\": f\"https://www.reddit.com{submission.permalink}\",\n",
    "                \"source\": \"reddit_post\"\n",
    "            })\n",
    "\n",
    "        # Fetch comments\n",
    "        submission.comments.replace_more(limit=0)\n",
    "        for comment in submission.comments.list():\n",
    "            ctext = comment.body\n",
    "            if is_genai_edu(ctext):\n",
    "                out.append({\n",
    "                    \"title\": f\"Comment on: {submission.title}\",\n",
    "                    \"content\": ctext,\n",
    "                    \"published_at\": datetime.utcfromtimestamp(comment.created_utc),\n",
    "                    \"url\": f\"https://www.reddit.com{comment.permalink}\",\n",
    "                    \"source\": \"reddit_comment\"\n",
    "                })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "def main():\n",
    "    collected = []\n",
    "    print(\"Fetching NewsAPI...\")\n",
    "    collected.extend(fetch_newsapi())\n",
    "    print(\"Fetching Medium...\")\n",
    "    collected.extend(fetch_medium())\n",
    "    print(\"Fetching Reddit...\")\n",
    "    collected.extend(fetch_reddit())\n",
    "\n",
    "    print(f\"Collected {len(collected)} raw items\")\n",
    "    final = dedupe([r for r in collected if is_genai_edu(r.get(\"content\",\"\"))])\n",
    "    print(f\"Filtered down to {len(final)} Generative AI in Education articles\")\n",
    "\n",
    "    if final:\n",
    "        df = pd.DataFrame(final)\n",
    "        df.to_csv(OUTPUT_FILE, index=False)\n",
    "        print(f\"Saved {len(final)} articles to {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
